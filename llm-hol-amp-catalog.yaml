name: Hands on Lab focused on LLMs

entries:
  - title: LLAMA-2-7B Standalone Model Deployment
    label: llm-model-deploy
    short_description: |
      This AMP deploys LLAMA-2-7B model as a CML API endpoint. Requires a GPU node with 4 vCores and 16 GB memory minimum.
    long_description: |
      This AMP deploys LLAMA-2-7B model as a CML API endpoint. Requires a GPU node with 4 vCores and 16 GB memory minimum.
    image_path: "https://raw.githubusercontent.com/ogakulov/shared-fm/main/images/human-ml-unsplash.jpg"
    tags: 
      - LLM
      - LLAMA
      - Model Deployment
    git_url: "https://github.com/ogakulov/shared-fm"
    is_prototype: true